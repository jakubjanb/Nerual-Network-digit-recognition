{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247b4e70",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier vs. Neural Network for the hand written digits classification\n",
    "\n",
    "Here we present a basic and well-known example for the application of neural networks: **recognising handwritten digits**. We compare two standard methods known in machine learning, i.e. **decision trees** and **neural networks**, and we compare their performance. For neural networks, we use two approaches. The first is a simple neural network with no hidden layers. Then we add **hidden layers** to the network to observe the increase in the method's effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe45dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import all the necessary packages and functions\n",
    "# We are using Python scikit-learn Machine Learning library and MNIST (database of handwritten digits)\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "import random\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c676a",
   "metadata": {},
   "source": [
    "X is array of instances and y is a vector of labels \n",
    "\n",
    "Next, we will divide the data into a **training set** and **test set**, randomly selecting 5000 examples for training (train_samples = 5000) and 1000 examples for testing (test_size = 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 5000\n",
    "\n",
    "# X is in pandas format for some reason. Convert to numpy.\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07649249",
   "metadata": {},
   "source": [
    "X_train, y_train are instances & labels for training AND X_test, y_test are instances & labels for testing\n",
    "\n",
    "An instance, in this case, is a vector of 784 (that is 28 x 28 grid of pixels turned into the vector). Integers between 0 and 255 indicate the brightness of the pixel with 255 the pixel is fully activated (bright), and 0 the pixel is black\n",
    "\n",
    "Below we print out one random example of the vector from the testing set with its label. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc82f3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  15.  76. 104.\n",
      " 168. 202. 179. 138.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  83. 232. 254. 180.\n",
      " 126. 126. 169. 254.  69.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  79. 249. 210.  54.   6.\n",
      "   0.   0.  42. 254. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  74. 249. 166.  12.   0.   0.\n",
      "   0.   0.  42. 254. 159.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  10. 209. 252.  48.   0.   0.   0.\n",
      "   0.   0.  33. 247. 176.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  19. 236. 245.   5.   0.   0.   0.\n",
      "   0.   0.  14. 232. 165.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  89. 224.  80.   0.   0.   0.   0.\n",
      "   0.   0.  98. 254. 104.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 183.  58.   0.   0.   0.   0.   0.\n",
      "   0.   0. 182. 254.  43.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 107.  44.   0.   0.   0.   0.   0.\n",
      "   0.  14. 233. 231.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. 126. 254. 151.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. 167. 254.  45.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  14. 241. 229.  27.  61.  52.  66.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 113. 194.\n",
      " 246. 254. 254. 254. 251. 199.  75.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  12.  68.\n",
      " 213. 254. 144. 110.  34.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 141. 253.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 200. 247.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 217. 246.  26.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  15.\n",
      " 232. 232.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  99.\n",
      " 255. 126.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  58.\n",
      " 224.  61.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "The number that labels this instance: 7\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(0, len(X_train))\n",
    "print(X_train[i])\n",
    "print(\"The number that labels this instance:\", y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e19c0b",
   "metadata": {},
   "source": [
    "Below we present a graphical representation of the instance \" i \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07a60719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.array(X_train[i]).reshape(28,28)\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417cff4a",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "Here we use the decision tree to classify the number into the correct category. We can alter the classifier's precision by changing the number of leaves (max_leaf_nodes). A tree with fewer decision rules (leaves) performs worst, but adding more decision rules than some number (here around 160) does not increase the precision of this method. As an output, we can compute the **accuracy** of this method for a given number of leaves. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bee73016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes = 160)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "  if clf.predict([X_test[i]]) == y_test[i]: correct = correct + 1\n",
    "  acc = [100.0* correct / len(X_test)]\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ffb92",
   "metadata": {},
   "source": [
    "## Neural Network Classifier\n",
    "Here we are using MLPClassifier (MLP stands for **multi-layer perceptron** or **neural network**) \n",
    "\n",
    "*hidden_layer_sizes = []* is an empty list, since here we do not consider any hidden leyers\n",
    "\n",
    "*max_iter = 10000* - we train network no more then 10000 iterations \n",
    "\n",
    "*activation = 'identity'* - since we are using linear activation \n",
    "\n",
    "The architecture of this network consists of 784 input nodes for each pixel and 10 output nodes for numbers from 0 to 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7f8bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=[], max_iter = 10000, activation = 'identity')\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389bcdf",
   "metadata": {},
   "source": [
    "## Neural Network with hidden layer\n",
    "Now, we will add one **hidden layer** and expand the number of **hidden units** from 10 to 200 in intervals of 10. \n",
    "We'll print the accuracy of each model given the number of hidden units.\n",
    "\n",
    "Here we ara using ReLU activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9614eedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden units: 10 ; Accuracy 0.362\n",
      "Number of hidden units: 20 ; Accuracy 0.697\n",
      "Number of hidden units: 30 ; Accuracy 0.869\n",
      "Number of hidden units: 40 ; Accuracy 0.887\n",
      "Number of hidden units: 50 ; Accuracy 0.849\n",
      "Number of hidden units: 60 ; Accuracy 0.854\n",
      "Number of hidden units: 70 ; Accuracy 0.88\n",
      "Number of hidden units: 80 ; Accuracy 0.885\n",
      "Number of hidden units: 90 ; Accuracy 0.889\n",
      "Number of hidden units: 100 ; Accuracy 0.893\n",
      "Number of hidden units: 110 ; Accuracy 0.901\n",
      "Number of hidden units: 120 ; Accuracy 0.877\n",
      "Number of hidden units: 130 ; Accuracy 0.91\n",
      "Number of hidden units: 140 ; Accuracy 0.894\n",
      "Number of hidden units: 150 ; Accuracy 0.913\n",
      "Number of hidden units: 160 ; Accuracy 0.907\n",
      "Number of hidden units: 170 ; Accuracy 0.893\n",
      "Number of hidden units: 180 ; Accuracy 0.902\n",
      "Number of hidden units: 190 ; Accuracy 0.893\n",
      "Number of hidden units: 200 ; Accuracy 0.909\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "  nhidden = i*10\n",
    "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000)\n",
    "  clf.fit(X_train, y_train)\n",
    "  score = clf.score(X_test, y_test)\n",
    "  print(\"Number of hidden units:\", nhidden, \";\", \"Accuracy\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd720fa2",
   "metadata": {},
   "source": [
    "We can see that model reaches its maximum accuracy of around 150 hidden units. \n",
    "Next, we train it ten times with 150 hidden units to see how a model varies across multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a98ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.912\n",
      "150 0.891\n",
      "150 0.901\n",
      "150 0.886\n",
      "150 0.896\n",
      "150 0.903\n",
      "150 0.888\n",
      "150 0.905\n",
      "150 0.896\n",
      "150 0.894\n"
     ]
    }
   ],
   "source": [
    "nhidden = 150\n",
    "for i in range(10):\n",
    "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000)\n",
    "  clf.fit(X_train, y_train)\n",
    "  score = clf.score(X_test, y_test)\n",
    "  print(nhidden,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038cc181",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Here we have compared the performance of the Decision Tree Classifier and simple Neural Network for written digit recognition. We can observe improved performance for Neural Networks compared to Decision Tree, and adding a hidden layer increases the accuracy of the model even higher to around 90%. Nevertheless, there is still space for significant improvement since 90% does not seem good enough for practical use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b51f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
